---
title: "Introducing Minions Prompts: GitHub for Your Prompts"
description: "Why prompt engineering needs version control, testing, and A/B comparison — and how Minions Prompts delivers all three."
date: 2026-02-20
author: "Mehdi Nabhani"
tags: ["announcement", "prompts", "versioning"]
draft: false
---

# Version Control for Prompt Engineering

Prompt engineering is the new programming — but unlike traditional code, prompts live in spreadsheets, sticky notes, and Slack threads. There's no `git diff`, no test suite, no way to know which version of a prompt works best in production.

**Minions Prompts** fixes that.

<Callout type="info">
Minions Prompts is an open-source system built on the Minions SDK that brings version control, testing, and A/B comparison to prompt engineering workflows.
</Callout>

## The Prompt Engineering Problem

Every team working with LLMs runs into the same issues:

1. **Version chaos** — "Which version of the summarization prompt are we using?"
2. **No testing** — Prompt changes go live without systematic validation
3. **Gut-feel tuning** — A/B comparisons happen informally, if at all
4. **No rollback** — When a prompt regresses, there's no easy way to revert

## How Minions Prompts Helps

### Template Versioning

Every prompt is a versioned template with variable interpolation.

```typescript
import { createMinionsPrompts } from '@minions-prompts/sdk';

const client = createMinionsPrompts();

// Create a prompt template
const template = await client.templates.create({
  name: 'summarizer',
  content: 'Summarize the following {{format}}: {{text}}',
  variables: ['format', 'text'],
  tags: ['summarization', 'production']
});

// Create a new version
const v2 = await client.templates.createVersion(template.id, {
  content: 'You are a precise summarizer. Summarize the following {{format}} in {{maxWords}} words or fewer: {{text}}',
  variables: ['format', 'text', 'maxWords'],
  changelog: 'Added word limit constraint'
});
```

### Test-Driven Prompt Development

Write test cases for your prompts just like you write unit tests for code.

```typescript
const testSuite = await client.tests.create({
  templateId: template.id,
  cases: [
    {
      input: { format: 'article', text: 'Long article content...' },
      assertions: [
        { type: 'maxLength', value: 200 },
        { type: 'contains', value: 'key finding' }
      ]
    }
  ]
});
```

### A/B Comparison

Compare prompt versions head-to-head with real inputs and automated scoring.

```typescript
const comparison = await client.compare({
  templateId: template.id,
  versionA: 'v1',
  versionB: 'v2',
  testCases: testSuite.cases
});

console.log(`v1 score: ${comparison.scoreA}`);
console.log(`v2 score: ${comparison.scoreB}`);
console.log(`Winner: ${comparison.winner}`);
```

<Callout type="tip">
Start with simple assertions (length, keyword presence) and gradually add more sophisticated scoring as your testing practice matures.
</Callout>

## What's Next?

We're building the CLI, expanding the Python SDK, and developing a full web playground. Check out the [documentation](https://prompts.minions.help) and join us on [GitHub](https://github.com/mxn2020/minions-prompts)!
